{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "<table align=\"left\" width=100%>\n",
    "    <td>\n",
    "        <div style=\"text-align: center;\">\n",
    "          <img src=\"./images/bar.png\" alt=\"entidades financiadoras\"/>\n",
    "        </div>\n",
    "    </td>\n",
    "    <td>\n",
    "        <p style=\"text-align: center; font-size:24px;\"><b>Introduction to Data Science</b></p>\n",
    "        <p style=\"text-align: center; font-size:18px;\"><b>Master in Electrical and Computer Engineering</b></p>\n",
    "        <p style=\"text-align: center; font-size:14px;\"><b>Pedro Cardoso (pcardoso@ualg.pt)</b></p>\n",
    "    </td>\n",
    "</table>\n",
    "\n",
    "_____\n",
    "\n",
    "__Short Lesson Title:__ Efficient Time Series Data Storage and Management\n",
    "\n",
    "*__Summary:__ This optional lesson focuses on efficient storage and management of time series data. Students will learn about different data structures and formats suitable for time series, including considerations for large datasets. The lesson may cover techniques for optimizing data storage and retrieval, potentially including database technologies or specialized libraries designed for time series data. Students will gain an understanding of best practices for handling and managing time series data effectively.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and retrieving TS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Time series Storage\n",
    "\n",
    "Time series data is a collection of observations made over time that are often used in many different applications such as financial analysis, environmental monitoring, and industrial control systems. The data is typically collected at regular intervals, and each observation is associated with a timestamp that indicates the time at which it was recorded. The storage and management of time series data are critical considerations for any application that relies on this data.\n",
    "\n",
    "## Storage Formats\n",
    "\n",
    "Time series data is usually stored in a tabular format, where each row corresponds to an observation, and each column represents a variable or attribute of that observation. The first column of the table is typically a timestamp column, which stores the time at which each observation was recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "One common file format used to store time series data is the CSV (Comma Separated Values) file format. A CSV file is a plain text file that contains a table of data, with each row separated by a newline character, and each column separated by a comma. CSV files are simple and widely supported, but they may not be the most efficient format for storing large amounts of time series data.\n",
    "\n",
    "Alternatively, the data can be stored in a tab-separated format, where each column is separated by a tab character (.tsv), or in a space-separated format, where each column is separated by a space character. \n",
    "\n",
    "The CSV file format is a plain text file format that is used to store tabular data.\n",
    "\n",
    "Example of a CSV file to store a time series\n",
    "```csv\n",
    "timestamp,value\n",
    "2020-01-01 00:00:00,0.0\n",
    "2020-01-01 00:01:00,0.1\n",
    "2020-01-01 00:02:00,0.2\n",
    "2020-01-01 00:03:00,0.3\n",
    "2020-01-01 00:04:00,0.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### XML\n",
    "Another file format used for storing time series data is the XML (Extensible Markup Language) file format. XML is a text-based file format that is used to store structured data, such as time series data. XML files are human-readable and widely supported, but they may not be the most efficient format for storing large amounts of time series data.\n",
    "\n",
    "Example of an XML file to store a time series\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<timeseries>\n",
    "    <timestamp>2020-01-01 00:00:00</timestamp>\n",
    "    <value>0.0</value>\n",
    "</timeseries>\n",
    "<timeseries>\n",
    "    <timestamp>2020-01-01 00:01:00</timestamp>\n",
    "    <value>0.1</value>\n",
    "</timeseries>\n",
    "<timeseries>\n",
    "    <timestamp>2020-01-01 00:02:00</timestamp>\n",
    "    <value>0.2</value>\n",
    "</timeseries>\n",
    "<timeseries>\n",
    "    <timestamp>2020-01-01 00:03:00</timestamp>\n",
    "    <value>0.3</value>\n",
    "</timeseries>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Excel\n",
    "Another file format used for storing time series data is the Excel file format. Excel files are binary files that contain a table of data, with each row stored separately. Excel files are widely supported and can be used to store large amounts of time series data, but they are not human-readable and may not be the most efficient format for storing large amounts of time series data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### JSON\n",
    "Another file format used for storing time series data is the JSON (JavaScript Object Notation) file format. JSON is a text-based file format that is used to store structured data, such as time series data. JSON files are human-readable and widely supported, but they may not be the most efficient format for storing large amounts of time series data.\n",
    "\n",
    "Example of a JSON file to store a time series\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"timestamp\": \"2020-01-01 00:00:00\",\n",
    "        \"value\": 0.0\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": \"2020-01-01 00:01:00\",\n",
    "        \"value\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": \"2020-01-01 00:02:00\",\n",
    "        \"value\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": \"2020-01-01 00:03:00\",\n",
    "        \"value\": 0.3\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Parquet\n",
    "Parquet is a columnar storage format that is used to store time series data. Parquet files are binary files that contain a table of data, with each column stored separately. Parquet files are efficient for storing large amounts of time series data, but they are not human-readable and may not be widely supported. E.g., see [here](https://parquet.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### HDF5\n",
    "Another file format used for storing time series data is the HDF5 (Hierarchical Data Format version 5) file format. HDF5 is a binary file format that supports the storage of large and complex data sets, including time series data. HDF5 files can store metadata, data attributes, and data types, and are designed for efficient storage and retrieval of large datasets.\n",
    "\n",
    "The structure of an HDF5 file is hierarchical, with groups and datasets. Groups are used to organize datasets into a hierarchy, and datasets are used to store the actual data. Datasets can be multidimensional arrays, and they can be compressed to reduce the size of the file. HDF5 files are efficient for storing large amounts of time series data, but they are not human-readable and may not be widely supported. Besides, the include metadata and data attributes can be used to store additional information about the data. HDF5 files can be accessed using a variety of programming languages, including Python, R, and MATLAB.\n",
    "\n",
    "Further information about the HDF5 file format can be found [here](https://portal.hdfgroup.org/documentation/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As an exampls, let us store a time series in a HDF5 file. We  will use the house consumption data set available in csv format on folder `data/house_consumption_TS/house_consumption.csv`. The data set contains measurements of electric power consumption in one household with a 15-minute sampling where the first column is the date and time, and the second column is the power consumption in kilowatts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:08.950637Z",
     "start_time": "2024-05-06T09:46:08.436323Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# read the data from the CSV file\n",
    "df = pd.read_csv('./data/house_consumption_TS/house_consumption.csv', header=0, parse_dates=['date'], index_col=['date'])\n",
    "\n",
    "# resample the data to hourly intervals\n",
    "df = df.resample('h').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Using h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:08.956872Z",
     "start_time": "2024-05-06T09:46:08.952298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new HDF5 file\n",
    "with h5py.File('./data/house_consumption_TS/house_consumption.hdf5', 'w') as f:\n",
    "\n",
    "    # create a dataset to store the time series data\n",
    "    dset = f.create_dataset('house_consumption', data=df)\n",
    "    \n",
    "    # define the attributes of the dataset\n",
    "    dset.attrs['CLASS'] = 'TIMESERIES'\n",
    "    dset.attrs['NAME'] = 'HOUSE_CONSUMPTION'\n",
    "    dset.attrs['START'] = str(df.index.min())\n",
    "    dset.attrs['COUNT'] = len(df)\n",
    "    dset.attrs['FREQUENCY (hours)'] = 1\n",
    "    dset.attrs['TIMEZONE'] = 'UTC'\n",
    "    dset.attrs['UNITS'] = 'kilowatts'\n",
    "    dset.attrs['DESCRIPTION'] = 'House consumption time series in kilowatts'\n",
    "    dset.attrs['SHAPE'] = df.shape\n",
    "    dset.attrs['TYPE'] = 'FLOAT32'\n",
    "    dset.attrs['AUTHOR'] = 'John Doe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To use the data in the HDF5 file, we can open the file and read the data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:08.965635Z",
     "start_time": "2024-05-06T09:46:08.957553Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"house_consumption.hdf5\" (mode r)>\n",
      "keys: <KeysViewHDF5 ['house_consumption']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-04 10:00:00</th>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 11:00:00</th>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 12:00:00</th>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 13:00:00</th>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 14:00:00</th>\n",
       "      <td>1.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 20:00:00</th>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 21:00:00</th>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 22:00:00</th>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 23:00:00</th>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-17 00:00:00</th>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17079 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "2021-02-04 10:00:00  0.764\n",
       "2021-02-04 11:00:00  0.972\n",
       "2021-02-04 12:00:00  0.936\n",
       "2021-02-04 13:00:00  0.946\n",
       "2021-02-04 14:00:00  1.112\n",
       "...                    ...\n",
       "2023-01-16 20:00:00  0.769\n",
       "2023-01-16 21:00:00  0.454\n",
       "2023-01-16 22:00:00  0.326\n",
       "2023-01-16 23:00:00  0.275\n",
       "2023-01-17 00:00:00  0.236\n",
       "\n",
       "[17079 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# open the HDF5 file\n",
    "with h5py.File('./data/house_consumption_TS/house_consumption.hdf5', 'r') as f:\n",
    "    print(f)\n",
    "    print(\"keys:\", f.keys())\n",
    "\n",
    "    df = pd.DataFrame(f['house_consumption'][:],\n",
    "                      index=pd.date_range(start=f['house_consumption'].attrs['START'],\n",
    "                                          periods=f['house_consumption'].attrs['COUNT'],\n",
    "                                          freq='h'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And the metadata can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:08.970374Z",
     "start_time": "2024-05-06T09:46:08.966331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** attributes: <Attributes of HDF5 object at 5335542224>\n",
      "** NAME attribute: HOUSE_CONSUMPTION\n",
      "** attributes keys: <KeysViewHDF5 ['AUTHOR', 'CLASS', 'COUNT', 'DESCRIPTION', 'FREQUENCY (hours)', 'NAME', 'SHAPE', 'START', 'TIMEZONE', 'TYPE', 'UNITS']>\n",
      "** attributes values: ValuesViewHDF5(<Attributes of HDF5 object at 5335542224>)\n",
      "** attributes items:\n",
      "AUTHOR : John Doe\n",
      "CLASS : TIMESERIES\n",
      "COUNT : 17079\n",
      "DESCRIPTION : House consumption time series in kilowatts\n",
      "FREQUENCY (hours) : 1\n",
      "NAME : HOUSE_CONSUMPTION\n",
      "SHAPE : [17079     1]\n",
      "START : 2021-02-04 10:00:00\n",
      "TIMEZONE : UTC\n",
      "TYPE : FLOAT32\n",
      "UNITS : kilowatts\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# open the HDF5 file\n",
    "f = h5py.File('./data/house_consumption_TS/house_consumption.hdf5', 'r')\n",
    "\n",
    "# read the dataset\n",
    "dset = f['house_consumption']\n",
    "\n",
    "# get the attributes\n",
    "print('** attributes:', dset.attrs)\n",
    "\n",
    "# since the `Attributes of HDF5 object` behaves like a dictionary, we can access the attributes as follows\n",
    "print('** NAME attribute:', dset.attrs['NAME'])\n",
    "\n",
    "# get the list of attributes\n",
    "print('** attributes keys:', dset.attrs.keys())\n",
    "\n",
    "# get the attributes values\n",
    "print('** attributes values:', dset.attrs.values())\n",
    "\n",
    "# or use the items() method to iterate over the attributes\n",
    "print('** attributes items:')\n",
    "for key, value in dset.attrs.items():\n",
    "    print(key, \":\",  value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Using pandas.HDFStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:08.973703Z",
     "start_time": "2024-05-06T09:46:08.972016Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !conda install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:09.116895Z",
     "start_time": "2024-05-06T09:46:08.974545Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('./data/house_consumption_TS/house_consumption_2.hdf5', 'w') as h:\n",
    "    df.to_hdf(h, key='house_consumption')\n",
    "    h.get_storer('house_consumption').attrs.metadata = {'CLASS': 'TIMESERIES',\n",
    "                                                        'NAME': 'HOUSE_CONSUMPTION',\n",
    "                                                        'START': str(df.index.min()),\n",
    "                                                        'COUNT': len(df),\n",
    "                                                        'FREQUENCY (hours)': 1,\n",
    "                                                        'TIMEZONE': 'UTC',\n",
    "                                                        'UNITS': 'kilowatts',\n",
    "                                                        'DESCRIPTION': 'House consumption time series in kilowatts',\n",
    "                                                        'SHAPE': df.shape,\n",
    "                                                        'TYPE': 'FLOAT32',\n",
    "                                                        'AUTHOR': 'John Doe'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:09.130896Z",
     "start_time": "2024-05-06T09:46:09.117853Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CLASS': 'TIMESERIES', 'NAME': 'HOUSE_CONSUMPTION', 'START': '2021-02-04 10:00:00', 'COUNT': 17079, 'FREQUENCY (hours)': 1, 'TIMEZONE': 'UTC', 'UNITS': 'kilowatts', 'DESCRIPTION': 'House consumption time series in kilowatts', 'SHAPE': (17079, 1), 'TYPE': 'FLOAT32', 'AUTHOR': 'John Doe'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-04 10:00:00</th>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 11:00:00</th>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 12:00:00</th>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 13:00:00</th>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04 14:00:00</th>\n",
       "      <td>1.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 20:00:00</th>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 21:00:00</th>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 22:00:00</th>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 23:00:00</th>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-17 00:00:00</th>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17079 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "2021-02-04 10:00:00  0.764\n",
       "2021-02-04 11:00:00  0.972\n",
       "2021-02-04 12:00:00  0.936\n",
       "2021-02-04 13:00:00  0.946\n",
       "2021-02-04 14:00:00  1.112\n",
       "...                    ...\n",
       "2023-01-16 20:00:00  0.769\n",
       "2023-01-16 21:00:00  0.454\n",
       "2023-01-16 22:00:00  0.326\n",
       "2023-01-16 23:00:00  0.275\n",
       "2023-01-17 00:00:00  0.236\n",
       "\n",
       "[17079 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pd.HDFStore('./data/house_consumption_TS/house_consumption_2.hdf5', 'r') as h:\n",
    "    _df = h['house_consumption']\n",
    "    metadata = h.get_storer('house_consumption').attrs.metadata\n",
    "    print(metadata)\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Storage and Indexing Strategie\n",
    "\n",
    "\n",
    "The storage and indexing of time series data are critical considerations for any application that relies on this data. The size of the dataset, the frequency of updates, and the types of queries that need to be supported can all impact the storage and indexing strategies that are used. Here are some common storage and indexing strategies for time series data:\n",
    "\n",
    "- __Columnar Storage__ - a storage format that stores data by column instead of by row. In columnar storage, each column of data is stored separately, which can improve the efficiency of certain types of queries, such as aggregation and filtering. Columnar storage is particularly well-suited for time series data because queries are often performed on a subset of the columns, rather than on the entire dataset. Columnar storage is used in several popular time series databases, such as InfluxDB and TimescaleDB.\n",
    "\n",
    "- __Compression__ - a technique used to reduce the size of data by encoding it in a more compact form. Compression can be particularly useful for time series data, which is often large and repetitive. There are several compression techniques that can be used for time series data, including delta encoding, run-length encoding, and gzip compression. Compression can reduce the amount of storage required for time series data, as well as improve the performance of queries by reducing the amount of data that needs to be read from disk.\n",
    "\n",
    "- __Partitioning__ - a technique used to split a dataset into smaller, more manageable pieces. Partitioning can be particularly useful for time series data, which is often too large to fit in memory or to be queried efficiently as a single unit. Partitioning can be done by time, where the dataset is split into chunks based on time intervals (e.g., hourly, daily, weekly), or by other criteria, such as location or sensor. Partitioning can improve query performance by allowing queries to be executed on a subset of the data, rather than the entire dataset. Partitioning is used in several popular time series databases, such as OpenTSDB and KairosDB.\n",
    "\n",
    "- __Indexing__ - a technique used to speed up queries by creating a data structure that maps query criteria to the location of the corresponding data in the dataset. Indexing is particularly useful for time series data, where queries often involve filtering on a specific time range or a subset of the data. There are several indexing techniques that can be used for time series data, including B-trees, bitmap indexes, and inverted indexes. Indexing can improve query performance by reducing the amount of data that needs to be scanned to retrieve the desired results. Indexing is used in several popular time series databases, such as OpenTSDB.\n",
    "\n",
    "## Time Series Databases\n",
    "\n",
    "Time series databases are specialized databases that are designed to store and query time series data efficiently. Time series databases use a combination of the storage and indexing strategies discussed above to provide fast and efficient storage and retrieval of time series data. Here are some popular time series databases:\n",
    "\n",
    "- __InfluxDB__ - a popular open-source time series database that is designed for high write and query performance. InfluxDB uses a columnar storage format, compression, partitioning, and indexing to provide fast and efficient storage and retrieval of time series data. InfluxDB also supports a SQL-like query language called InfluxQL, which makes it easy to query and analyze time series data.\n",
    "\n",
    "- __TimescaleDB__ - an open-source time series database that is built on top of PostgreSQL. TimescaleDB uses a columnar storage format, compression, partitioning, and indexing to provide fast and efficient storage and retrieval of time series data. TimescaleDB also supports a SQL-like query language, and provides a number of advanced features, such as automatic data retention policies and continuous aggregates.\n",
    "\n",
    "- __OpenTSDB__ - a distributed time series database that is designed to handle large amounts of time series data. OpenTSDB uses a row-based storage format, partitioning, and indexing to provide fast and efficient storage and retrieval of time series data. OpenTSDB also provides a powerful query language that allows users to perform complex queries on time series data.\n",
    "\n",
    "- __KairosDB__ - a time series database that is built on top of Apache Cassandra. KairosDB uses a columnar storage format, compression, partitioning, and indexing to provide fast and efficient storage and retrieval of time series data. KairosDB also provides a REST API that makes it easy to integrate with other applications.\n",
    "\n",
    "Of course, relational databases (e.g., MySQL) or documental databases (MongoDB) can also be used, at least as an inital solutiom\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The storage and management of time series data are critical considerations for any application that relies on this data. Time series data is typically stored in a tabular format with a timestamp column and one or more columns containing the corresponding data values. Time series data can be stored in a variety of file formats, including CSV, HDF5, and netCDF. The storage and indexing of time series data can impact query performance and storage efficiency. Columnar storage, compression, partitioning, and indexing are all techniques that can be used to optimize the storage and retrieval of time series data. Time series databases, such as InfluxDB, TimescaleDB, OpenTSDB, and KairosDB, provide specialized support for storing and querying time series data efficiently. Overall, the optimal storage and management of time series data require a combination of techniques and tools that are tailored to the specific use case and requirements of the application.\n",
    "\n",
    "In addition to the techniques and tools discussed above, there are several emerging technologies that are being used to manage and analyze time series data. For example, Apache Kafka is a distributed streaming platform that can be used to ingest, process, and store high-volume real-time data streams, including time series data. Apache Flink is a distributed stream processing framework that can be used to perform real-time analytics on data streams, including time series data. These technologies can be used in conjunction with time series databases and other tools to build end-to-end time series data pipelines that can handle large-scale data processing and analysis tasks.\n",
    "\n",
    "In conclusion, time series data is an essential component of many applications, and the efficient storage and management of this data are critical to the success of these applications. Time series data can be stored in a variety of file formats, and the choice of storage format can impact query performance and storage efficiency. Several techniques, including columnar storage, compression, partitioning, and indexing, can be used to optimize the storage and retrieval of time series data. Time series databases provide specialized support for storing and querying time series data efficiently, and emerging technologies, such as Apache Kafka and Apache Flink, can be used to build end-to-end time series data pipelines that can handle large-scale data processing and analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:46:09.133327Z",
     "start_time": "2024-05-06T09:46:09.131826Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "<table align=\"left\" width=100%>\n",
    "    <td>\n",
    "        <div style=\"text-align: center;\">\n",
    "          <img src=\"./images/bar.png\" alt=\"entidades financiadoras\"/>\n",
    "        </div>\n",
    "    </td>\n",
    "    <td>\n",
    "        <p style=\"text-align: center; font-size:24px;\"><b>Introduction to Data Science</b></p>\n",
    "        <p style=\"text-align: center; font-size:18px;\"><b>Master in Electrical and Computer Engineering</b></p>\n",
    "        <p style=\"text-align: center; font-size:14px;\"><b>Pedro Cardoso (pcardoso@ualg.pt)</b></p>\n",
    "    </td>\n",
    "</table>\n",
    "\n",
    "_____\n",
    "\n",
    "__Short Lesson Title:__ Pandas DataFrames: Creation and Manipulation\n",
    "\n",
    "*__Summary:__ This lesson introduces the fundamental concepts of Pandas DataFrames, the core data structure for data analysis in Python. Students will learn how to create DataFrames from various data sources, including NumPy arrays, Pandas Series, Python dictionaries, and external files (CSV, JSON, Excel). The lesson covers essential DataFrame attributes and methods for inspecting data, such as shape, info, describe, head, tail, index, and columns. It also delves into data selection and manipulation techniques using indexing, slicing, boolean indexing, and the loc, iloc, at, and iat methods. Students will learn how to sort data, add and modify rows and columns, handle missing data, and perform basic statistical operations. Finally, the lesson explores data concatenation, merging, grouping, and basic plotting, providing a comprehensive foundation for working with DataFrames.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "\n",
    "A __data frame__ is a way to store data in \"rectangular\" grids\n",
    "* Each row corresponds to measurements or values of an instance, \n",
    "* Each column is a vector containing data for a specific variable. \n",
    "* Data frame’s rows do not need to contain, but can contain, the same type of values: they can be numeric, character, boolean, etc.\n",
    "\n",
    "So, dataFrames in the Pandas library are defined as a __two-dimensional labeled data structures__ with columns of potentially different types.\n",
    "       \n",
    "Pandas' DataFrame consists of three main components: the data, the index, and the columns.\n",
    "       \n",
    "The DataFrame can contain data that is:\n",
    "* **Heterogeneous**: Each column can have a different data type (numeric, string, boolean, etc.).\n",
    "* **Labeled**: Both rows (index) and columns have labels, making it easy to access and manipulate data.\n",
    "* **Missing Values**: DataFrames can handle missing or NaN values seamlessly, which is important for data cleaning and preprocessing.\n",
    "* **Size-Mutable**: DataFrames can grow or shrink in size, allowing for dynamic data manipulation.\n",
    "* **Data Alignment**: DataFrames automatically align data based on the index and column labels, making it easy to perform operations on different DataFrames.\n",
    "* etc. \n",
    " \n",
    " \n",
    "![images/01_table_dataframe.svg](images/01_table_dataframe.svg)\n",
    "\n",
    "Let's start by importing the libraries we will need for this notebook and set inline plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataframe\n",
    "\n",
    "So, many things can serve as input to make a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Dataframe is an empty one as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### From a numpy array (`nparray`)\n",
    "\n",
    "To create a DataFrame from a numpy array, we can use the `pd.DataFrame` constructor.  The `data` parameter is the numpy array to be converted to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1,2],\n",
    "                [3,4]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **define an index and name the columns**. The `index` parameter is the index of the DataFrame. The `columns` parameter is the columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=data,\n",
    "             index=['row 1', 'row 2'],\n",
    "             columns=['col 1', 'col 2']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T14:04:17.414628Z",
     "start_time": "2019-04-02T14:04:17.409633Z"
    }
   },
   "source": [
    "We can also use a structured array as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = np.array(\n",
    "    [\n",
    "        ('Olivia', 1, 13.0),\n",
    "        ('Violeta Maria', 3, 5.0)    \n",
    "    ],\n",
    "    dtype=[('name', 'U10'),   # 10-character string\n",
    "           ('age', 'i4'),     # 4-byte signed integer\n",
    "           ('weight', 'f4')]  # 4-byte floating-point number\n",
    ")\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pets)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pandas' Series\n",
    "\n",
    "As seen in the previous notebook, a Pandas' Series is a one-dimensional labeled array capable of holding any data type with axis labels or index. \n",
    "\n",
    "Further, an example of a Series object is one column from a DataFrame.\n",
    "\n",
    "But, let us create a DataFrame from a set Series. For example, the following Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "name = pd.Series(['Margaret', 'John', 'Claudia', 'Mary', 'Peter', 'Helga', 'Heidi', 'Mary'])\n",
    "\n",
    "age = pd.Series([17, 13, 44, 55, 71, 7, 16, 70])\n",
    "\n",
    "gender = pd.Series(['F', 'M', 'F', 'F', 'M', 'F', 'F', 'F'])\n",
    "\n",
    "classification = pd.Series([4, 3, 2, 5, 1, 7, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the `name` Series is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the building of the data frame is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = pd.DataFrame(data=[name, age, gender, classification],\n",
    "                          # columns=range(8), # this is the default\n",
    "                          index=['name', 'age', 'gender', 'classification']\n",
    "                         )\n",
    "\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer, the dataframe can be transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:51:50.165170Z",
     "start_time": "2018-04-05T16:51:50.161167Z"
    }
   },
   "source": [
    "Unless explicitly done, most of the operation are **NOT done \"inline\"**. So, we must store the returned data (or use the `inplace` argument, if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = persons_df.T # equivalent to persons_df.transpose()\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a Python's Dictionary\n",
    "\n",
    "A dictionary is a collection which is unordered, changeable and indexed. In Python dictionaries are written with curly brackets, and they have keys and values. Passing a dictionary to the DataFrame constructor will interpret the dictionary keys as the column names and the dictionary values as the data for those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = pd.DataFrame({\n",
    "    'name': name,\n",
    "    'age': age,\n",
    "    'gender': gender,\n",
    "    'country': 'Pt',\n",
    "    'pet': ['cat', 'dog', 'fish', 'cat', 'cat', 'fish', 'bird', 'cat'],\n",
    "    'height': [170, 172, 178, 160, 165, 150, 151, np.nan],\n",
    "    'classification': classification\n",
    "})\n",
    "\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## How To Create an Empty DataFrame\n",
    "\n",
    "As already seen, the method that we'll use is the Pandas' `Dataframe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame()\n",
    "empty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use this function to make an empty DataFrame and use `numpy.nan` to initialize your data frame with NaNs. NaNs are used to indicate that the data is not available or missing. Note that `numpy.nan` has type float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(np.nan, \n",
    "                        index=[0, 1, 2, 3], \n",
    "                        columns=['A'])\n",
    "empty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force the dataFrame to be of a certain type by adding the attribute `dtype` and filling in the desired type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(index=range(0,4),\n",
    "                        columns=['A'], \n",
    "                        dtype='float')\n",
    "empty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get information from the Dataframe?\n",
    "\n",
    "Returning to the person's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` attribute of the Dataframe returns a tuple with the number of rows and columns `(number of rows, number of columns)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = persons_df.shape\n",
    "print(f'The number of rows is {m} and the number of columns is {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get the number of rows is to use the `len` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(persons_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use function `count` to get to know more about the number of elements in your dataFrame. However,  this will exclude the NaN values (if there are any - see the `height` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the values in the dataframe we can use the `values` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a statiscal description of the data can be obtained with the `describe` method. For example, the mean, standard deviation, minimum and maximum values, and the quartiles. These are only computed for the numerical columns.\n",
    "\n",
    " For the non-numerical columns, the count, unique, top, and freq values are returned instead but only if the `include` parameter is set to `all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.describe(include='all')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and more information can be obtained with the `info` method, such as the number of non-null values, the type of the data, and the memory usage. The memory usage is not very accurate, but it is a good indication. To get the exact memory usage we can use the `memory_usage` parameter and set it to `deep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set the index\n",
    "\n",
    "The index is a way to identify each row in the dataframe. To set the index we can use the `set_index` method of the dataframe. The `set_index` method returns a new DataFrame with the new index. The original DataFrame is not modified. To modify the original DataFrame we can use the `inplace` argument and set it to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_index_by_name = persons_df.set_index('name')\n",
    "\n",
    "persons_df_index_by_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the index is now the name, we can use it to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_index_by_name.loc['Margaret']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since _Mary_ is repeated, we get a dataframe with all the rows with the name/index _Mary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_index_by_name.loc['Mary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save data\n",
    "Pandas allows us to load and save data from several formats. For example, we can **save** data to csv, json, excel, and many more. We can also **load** data from csv, json, excel, and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl # you might need to install this package to load and save data to excel files\n",
    "\n",
    "persons_df.to_csv('persons.csv')\n",
    "persons_df.to_json('persons.json')\n",
    "persons_df.to_excel('persons.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load data from csv, json, excel, and many more type use the appropriate read function. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_temp = pd.read_csv('persons.csv')\n",
    "persons_another_temp = pd.read_json('persons.json')\n",
    "persons_another_another_temp = pd.read_excel('persons.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read data from a url containing a csv file, we can use the `read_csv` function. For example, we can read the iris dataset from the pandas github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/iris.data')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid downloading all the times we can save the data to a local file and then read it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    iris_df = pd.read_csv('iris.data.csv', index_col=0)\n",
    "    print('loaded from local iris.data.csv')\n",
    "except:\n",
    "    print('downloading...')\n",
    "    iris_df = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/iris.data')\n",
    "    print('done')\n",
    "    iris_df.to_csv('iris.data.csv')\n",
    "    print('saved to iris.data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data\n",
    "\n",
    "Recall what `persons_df` contains the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 5 lines of the dataframe can be obtained with the `head` method. If we want to get any other number    lines we can pass the number of lines as an argument to the `head` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to get the first 3 lines we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the last 5 lines of the dataframe we can use the `tail` method. If we want to get any other number of lines we can pass the number of lines as an argument to the `tail` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the index of the dataframe we can use the `index` attribute. In this case, the returned object is a `RangeIndex` object, which is a memory-efficient representation of a sequence of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the index of the persons_df_index_by_name we can see that it is a `Index` object, which is a memory-efficient representation of an immutable sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_index_by_name.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the columns of the dataframe we can use the `columns` attribute. The returned object is a `Index` object, which is also a memory-efficient representation of an immutable sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    "The Python and NumPy indexing operators [] and attribute operator \".\" provide quick and easy access to pandas data structures across a wide range of use cases. This makes interactive work intuitive, as there’s little new to learn if you already know how to deal with Python dictionaries and NumPy arrays. However, since the type of the data to be accessed isn’t known in advance, directly using standard operators has some optimization limits.\n",
    "\n",
    "For example, it possible to do row slicing, as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the 1st and 2nd rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get up to the 3rd line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get data every two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the following is not slicing, so it will issue a `KeyError` error exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being an exception you can catch it with a try/except block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    persons_df[1]\n",
    "except KeyError as ke:\n",
    "    print(\"KeyError: \" + str(ke))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, you can get columns by name using the following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df['pet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 'pet' and 'gender' columns using a list of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[['pet', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:57:18.635093Z",
     "start_time": "2018-04-05T16:57:18.632092Z"
    }
   },
   "source": [
    "We can also access a series (column) using the dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.pet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `loc`, `iloc` and `at` methods\n",
    "\n",
    "For production code, we recommended that you take advantage of the optimized pandas data access methods exposed next, namely the the use `loc`, `iloc` and `at` methods\n",
    "\n",
    "* `loc` works on labels in the index.\n",
    "\n",
    "* `iloc` works on the positions in the index (so it only takes integers - 0-index notation).\n",
    "\n",
    "* `at` works similarly to `loc` but `at` provides label based scalar lookups (access a single value for a row/column label pair, so use `at` if you only need to get or set a single value in a DataFrame or Series).\n",
    "\n",
    "Lets us start by redefining the index of the `persons_df` dataframe to be the name of the person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = persons_df.set_index('name')\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row with the label 'Peter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['Peter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a 0-based index, the 5th row can be obtained with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us mesure the time it takes to get the row with the label 'Peter' using the `loc` and `iloc` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit is an ipython magic function, which can be used to time a particular piece of code (A single execution statement, or a single method). \n",
    "%timeit persons_df.loc['Peter']\n",
    "%timeit persons_df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice the dataframe from the 1st to first row which has the label 'Peter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc[:'Peter'] # 'Peter' is included!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the slicing must be done using index which are unique. If we try to slice using a non-unique index we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df.loc[:'Mary'] # 'Mary' is duplicated in the index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice up to the 4th row (not included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iloc[:4]  # 'Peter' is NOT included!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice from row labeled 'John' to row labeled 'Peter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['John':'Peter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simultaneouly, it is possible to do filters and projections at the same time using the `loc` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc[:'John', 'age':'country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `iloc` method, we can do a similar thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iloc[:2, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a specific value, we can do it differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['Peter','country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, since `persons_df.loc['Peter']` returns a Series, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['Peter']['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `iloc` method, we can do it differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iloc[4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['Peter', 'pet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.at['Peter', 'pet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iat[4, 3]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit persons_df.loc['Peter','pet']\n",
    "%timeit persons_df.at['Peter','pet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit persons_df.iloc[4, 3]\n",
    "%timeit persons_df.iat[4, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting data\n",
    "To sort the data, we can use the `sort_values` method. The default sorting is ascending, but we can change it to descending by setting the `ascending` parameter to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.sort_values(by='height', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort by multiple columns, by passing a list of column names to the `by` parameter. In this case, the first column will be used as the primary sorting key, and the second column will be used as the secondary sorting key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persons_df.sort_values(by=['pet', 'classification'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to sort the axis index, by using the `sort_index` method. \n",
    "\n",
    "Remember that the `axes` attribute returns a tuple with the index and the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the index in ascending order (default behaviour) we use the axis=0 parameter. This is the default behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.sort_index(axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the columns in ascending order (default behaviour) we use the axis=1 parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persons_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort both the index and the columns in the same call. In this case we use the dot notation to chain the two methods as each method returns a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_sorted = persons_df \\\n",
    "    .sort_index(axis=1) \\\n",
    "    .sort_index(axis=0)\n",
    "\n",
    "persons_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing\n",
    "Pandas also allows you to use boolean indexing to select the data rows that match a specified criterion. For example, we can select the rows where the value of the `height` column is greater than 170."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.height > 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[persons_df.height > 170]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isin` method can be used to filter the data using a list of values. For example, we can select the rows where the value of the `pet` column is either 'cat' or 'fish'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = persons_df.pet.isin(['cat', 'fish'])\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could also be done using the conjunction operator `&` (and) and the disjunction operator `|` (or)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = (persons_df.pet == 'cat') | (persons_df.pet == 'fish')\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example if we want to the persons with a cat which are Male we can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = (persons_df.pet == 'cat') & (persons_df.gender == 'M')\n",
    "persons_df[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and setting data (single value)\n",
    " To set a value in a DataFrame, we can use the `loc` or `iloc` methods.\n",
    "\n",
    " Remeber your `persons_df` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set a values by index/label we can use the `loc` method or the `at` method. The `at` method is faster than the `loc` method if the index is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['Peter', 'pet'] = 'iguana'\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df.at['Peter', 'pet'] = 'iguana'\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%timeit persons_df.loc['Peter', 'pet'] = 'iguana'\n",
    "%timeit persons_df.at['Peter', 'pet'] = 'iguana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_wihout_mary = persons_df.drop('Mary', axis=0)\n",
    "%timeit persons_wihout_mary.loc['Peter', 'pet'] = 'iguana'\n",
    "%timeit persons_wihout_mary.at['Peter', 'pet'] = 'iguana'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iloc` method is used to set a value by position. The `iat` method is faster than the `iloc` method. In this case, the i-th index is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.iloc[4, 3] = 'cat'\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df.iat[4, 3] = 'cat'\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%timeit persons_df.iloc[4, 3] = 'cat'\n",
    "%timeit persons_df.iat[4, 3] = 'cat'\n",
    "\n",
    "%timeit persons_wihout_mary.iloc[4, 3] = 'cat'\n",
    "%timeit persons_wihout_mary.iat[4, 3] = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persons_df.at['Peter', 'age'] = 44\n",
    "# persons_df.at['Peter', 'height'] = 185\n",
    "# persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persons_df.iat[0, 0] = 16\n",
    "# persons_df.iat[0, 4] = 168\n",
    "# persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and setting data (rows)\n",
    "So, how to update a row? or replace it? Easy peasy... we just use the `loc` method to set the values of the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the index does __not exist__ then a new row is added, i.e., the row is appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['George'] = [44, 'M', 'Pt', 'snake', 172.0, 8]\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the index __exists__ then the data is updated, i.e., the row is replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.loc['George'] = [34, 'M', 'Pt', 'iguana', 172.0, 8]\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding  and setting values (columns)\n",
    "\n",
    "We can add new Series/columns to the DataFrame by assigning them to the DataFrame. For example, we can add a new column called `weight` to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df['weight'] = [55, 58, 75, 64, 90, 20, 25, 78, 79]\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And operate Series. For instance the *body mass index* is defined as the body mass divided by the square of the body height,\n",
    "$$ BMI = \\frac{Weight}{Height^2}$$\n",
    "and is universally expressed in units of $kg/m^2$, resulting from mass in kilograms and height in metres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df['BMI'] = persons_df['weight'] / (persons_df['height']/100) ** 2\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if it is intended to say the person's weight category? We can use the `apply` method to apply a function to each element of the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_category(bmi):\n",
    "    return 'underweight' if bmi < 18.5  \\\n",
    "    else 'Normal weight' if 18.5 <= bmi < 25 \\\n",
    "    else 'Overweight'  if 25 <= bmi < 30 \\\n",
    "    else 'Obesity' if bmi >= 30 \\\n",
    "    else '?'\n",
    "\n",
    "persons_df['category'] = persons_df.BMI.apply(set_category)\n",
    "\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a row / Column\n",
    "\n",
    "To delete a row use the `drop` method with the index of the rows to be deleted. By default, the `drop` method returns a new DataFrame with the rows dropped, i.e., the default axis is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.drop(['Mary', 'George'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete a column use also the `drop` method but now tell it the `axis`, i.e., axis=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persons_df.drop(['pet'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also drop every cat lover! First we get the indexes of the cat lovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_people_indexes = persons_df.index[persons_df.pet == 'cat']\n",
    "cat_people_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.drop(cat_people_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop duplicates we can use the `drop_duplicates` method with the `keep` argument. If keep is `first` it keeps the first occurrence. If keep is `last` it keeps the last occurrence. If keep is `False` it drops all duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[['gender', 'pet']].drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df[['gender', 'pet']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "persons_df[['gender', 'pet']].drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations. Let us add some missing data to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_copy = persons_df.copy()\n",
    "persons_df_copy.at['Peter', 'club'] = 'Associação Académica de Coimbra'\n",
    "persons_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the info of the DataFrame we can see that the `club` column has 1 non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows that have missing data we can use the `dropna` method. This method returns a new DataFrame with the missing values dropped from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_with_full_data = persons_df_copy.dropna()\n",
    "persons_with_full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill missing data we can use the `fillna` method. This method returns a new DataFrame with the missing values filled or imputed with the value passed as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_with_filled_data = persons_df.copy()\n",
    "persons_with_filled_data['club'] = persons_df_copy['club'].fillna('SC Farense')\n",
    "persons_with_filled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the boolean mask where values are nan we can use the `isnull` method. Later we can use this mask to select the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df_copy.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stat operations in general exclude missing data. Examples of statistical operations include: `count`, `sum`, `mean`, `median`, `min`, `max`, `std`, `var`, `sem`, `skew`, `kurt`, `quantile`, `cumsum`, `cumprod`, `cummax`, `cummin`.\n",
    "\n",
    "These methods can be applied to the whole DataFrame or to a specific column. For example, to get the mean of all numerical columns we can use the `mean` method. The mean is given by \n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = persons_df.select_dtypes('number').columns\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.select_dtypes('number').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for a specific column like `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the same operation but on the other axis can also be done (it has no meaning in our case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median of all numerical columns is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank method computes the numerical data ranks (1 through n) along axis. By default, equal values are assigned a rank that is the average of the ranks of those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of all numerical columns is a measure that is used to quantify the amount of variation or dispersion of a set of data values. The standard deviation is given by\n",
    "$$ \\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute pairwise correlation between rows or columns of two DataFrame objects. The correlation os the Pearson correlation coefficient which is the covariance of the two variables divided by the product of their standard deviations. This values ranges from -1 to 1. A value of 1 means that there is a perfect positive correlation between the two variables. A value of -1 means that there is a perfect negative correlation between the two variables. A value of 0 means that there is no correlation between the two variables.\n",
    "\n",
    "The correlation between the height and the weight is given by\n",
    "$$ \\rho = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.height.corr(persons_df.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the correlation between all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df[numerical_columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count method returns the number of non-null values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique method returns the unique values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.pet.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append/concat & Merge\n",
    "Let us consider another dataframe with roughly the same set of columns as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_persons_df = pd.DataFrame({'name': ['Ronald', 'Christian'], \n",
    "                    'age': [23, 46], \n",
    "                    'gender': ['M', 'M'], \n",
    "                    'country':'Pt',\n",
    "                    'pet': ['turtle', 'iguana'],\n",
    "                    'height': [190, 181],\n",
    "                    'classification': [8, 9]\n",
    "                   }).set_index('name')\n",
    "more_persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can append/concat the new dataframe to the previous one (https://pandas.pydata.org/docs/reference/api/pandas.concat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df = pd.concat([persons_df, more_persons_df])\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge two dataframes (https://pandas.pydata.org/docs/reference/api/pandas.merge.html). Let us consider another dataframe with the number of legs of each pet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_info = pd.DataFrame({'pet': ['cat', 'dog', 'fish', 'bird', 'spider'],\n",
    "                         'pet_num_legs': [4, 4, 0, 2, 8],\n",
    "                         })\n",
    "pet_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The join of the tables is done based on some common column. In this case, the `pet` column. The default join is an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, on='pet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a left join and right join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, how='left', on='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, how='right', on='pet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merge can also be done on a specific column or the index of the dataframes. Let us consider the `pet_info` dataframe with the `pet` column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_info = pet_info.set_index('pet')\n",
    "pet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, left_on='pet', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, how='left', left_on='pet', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(persons_df, pet_info, how='right', left_on='pet', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps\n",
    "\n",
    "- Splitting the data into groups based on some criteria\n",
    "- Applying a function to each group independently\n",
    "- Combining the results into a data structure\n",
    "\n",
    "For example, we can count the number of instances by gender of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.groupby('gender').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or see the mean values (of the numerical columns) by gender. In this case, the columns have to be restricted to the numerical columns, otherwise the `mean` operation will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.groupby('gender')[numerical_columns].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or just for a single column (note that `persons_df.groupby('gender').height` is a SeriesGroupBy object, so we need to call the `mean` method to get the mean value, resulting in a Series object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.groupby('gender').height.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by a slightly different alternative (note that the result is a DataFrame object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(persons_df[['gender', \"height\"]].groupby('gender').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in some cases it makes no sense, we can sum the grouped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.groupby('gender')[numerical_columns].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the maximum value of the grouped values (between all full  defined rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.dropna().groupby('gender')[numerical_columns].prod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Other methods that can be used with `groupby` are `count`, `first`, `last`, `max`, `min`, `median`, `prod`, `std`, `sum`, `var`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if using jupyterthemes you should run the following commands to adequated colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyterthemes #if needed,\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data, if necessary\n",
    "try:\n",
    "    iris_df = pd.read_csv('iris.data.csv', index_col=0)\n",
    "    print('loaded from iris.data.csv')\n",
    "except:\n",
    "    print('downloading...')\n",
    "    iris_df = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/iris.data')\n",
    "    print('done')\n",
    "    iris_df.to_csv('iris.data.csv')\n",
    "    print('saved to iris.data.csv')\n",
    "\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see some relevant information about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and see a description of the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot method can be used to plot the data. By default, it plots the index on the x-axis and the values on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the data grouped by a column. In this case, the `Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.groupby('Name').plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot can be used to plot the data of two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = dict(zip(iris_df.Name.unique(), ['red', 'green', 'blue']))\n",
    "\n",
    "for t1 in ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']:\n",
    "    for t2 in ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']:\n",
    "        if t1 > t2:\n",
    "            iris_df.plot(x=t1, y=t2, kind='scatter', c=iris_df.Name.apply(lambda x : colors[x]))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of subplots can be useful to plot the data of all columns in a single figure. In this case, we use the `subplots` method of the `matplotlib` library, and define a 4 by 4 grid of subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "\n",
    "colors = dict(zip(iris_df.Name.unique(), ['red', 'green', 'blue']))\n",
    "for i1, t1 in enumerate(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']):\n",
    "    for i2, t2 in enumerate(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']):\n",
    "        if t1 != t2:\n",
    "            iris_df.plot(x=t1, y=t2, ax=axes[i1, i2], kind='scatter', c=iris_df.Name.apply(lambda x : colors[x]))\n",
    "        else:\n",
    "            iris_df[t1].plot(kind='hist', ax=axes[i1, i2], color='red', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more automatic way to plot the data is using the `scatter_matrix` method of the `pandas.plotting` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "_ = scatter_matrix(iris_df, figsize=(20, 20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see more plotings at http://pandas.pydata.org/pandas-docs/version/0.18/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inplace\n",
    "Some methods are allowed to be made inplace.  Let us remember the values of the `persons_df` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., the following sort of values will not affect the `persons_df` dataframe. In fact, it will return a new dataframe with the sorted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.sort_values(by=['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can use the `inplace` argument (depends no the methods). In this case, the `persons_df` dataframe will be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_df.sort_values(by=['age'], inplace=True)\n",
    "persons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Go to folder `exercises` and solve the exercises in notebook `03_exercises_US_names.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_IDC_metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "401px",
    "width": "554px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
